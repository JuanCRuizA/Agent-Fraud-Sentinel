{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 5: Streamlit Dashboard Prototype\n",
    "\n",
    "**Objective:** Build a professional, interactive dashboard that demonstrates enterprise-level fraud detection capabilities for a Data Scientist portfolio targeting banking roles.\n",
    "\n",
    "**Business Context:**  \n",
    "A fraud detection model is only as valuable as its ability to communicate results to stakeholders. This dashboard translates the XGBoost model and SHAP analysis from Phases 3-4 into an interactive tool for fraud analysts, business stakeholders, and compliance officers.\n",
    "\n",
    "**Who uses this dashboard?**\n",
    "- **Fraud analysts** -- monitor alerts, review flagged transactions, understand model decisions\n",
    "- **Business stakeholders** -- track KPIs, assess cost-benefit trade-offs\n",
    "- **Compliance & audit** -- verify regulatory readiness, review model governance\n",
    "\n",
    "---\n",
    "\n",
    "## Notebook Structure\n",
    "\n",
    "1. **Setup & Dependencies** -- Verify environment\n",
    "2. **Dashboard Architecture** -- Design overview\n",
    "3. **Streamlit Application** -- Complete app code (written to `dashboard_app.py`)\n",
    "4. **Tab Documentation** -- Design rationale for each tab\n",
    "5. **Deployment** -- Local and cloud deployment instructions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Setup & Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Verify all required packages are installed\n",
    "import importlib\n",
    "\n",
    "required = [\n",
    "    \"streamlit\", \"pandas\", \"numpy\", \"matplotlib\",\n",
    "    \"seaborn\", \"joblib\", \"sklearn\", \"xgboost\",\n",
    "    \"PIL\"  # Pillow\n",
    "]\n",
    "\n",
    "for pkg in required:\n",
    "    try:\n",
    "        mod = importlib.import_module(pkg)\n",
    "        version = getattr(mod, \"__version__\", \"installed\")\n",
    "        print(f\"  {pkg:<15s} {version}\")\n",
    "    except ImportError:\n",
    "        print(f\"  {pkg:<15s} ** MISSING ** -- pip install {pkg}\")\n",
    "\n",
    "print(\"\\nEnvironment check complete.\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Verify model artifacts and data files exist\n",
    "from pathlib import Path\n",
    "\n",
    "# Paths relative to notebooks/dashboard/\n",
    "MODEL_PATH = Path(\"../../models\")\n",
    "DATA_PATH = Path(\"../../data/processed\")\n",
    "FIGURES_PATH = Path(\"../../figures/shap\")\n",
    "\n",
    "artifacts = [\n",
    "    (MODEL_PATH / \"xgboost_final.pkl\", \"XGBoost model\"),\n",
    "    (MODEL_PATH / \"scaler.pkl\", \"StandardScaler\"),\n",
    "    (MODEL_PATH / \"threshold_config.pkl\", \"Threshold configuration\"),\n",
    "    (DATA_PATH / \"test.csv\", \"Test dataset\"),\n",
    "]\n",
    "\n",
    "shap_figures = [\n",
    "    \"shap_summary_beeswarm.png\",\n",
    "    \"shap_feature_importance_bar.png\",\n",
    "    \"shap_dependence_top4.png\",\n",
    "    \"shap_waterfall_cases.png\",\n",
    "    \"shap_fraud_vs_legit.png\",\n",
    "    \"shap_risk_tiers.png\",\n",
    "]\n",
    "\n",
    "print(\"Model Artifacts:\")\n",
    "for path, desc in artifacts:\n",
    "    status = \"OK\" if path.exists() else \"MISSING\"\n",
    "    print(f\"  [{status}] {desc}: {path}\")\n",
    "\n",
    "print(\"\\nSHAP Figures:\")\n",
    "for fig_name in shap_figures:\n",
    "    path = FIGURES_PATH / fig_name\n",
    "    status = \"OK\" if path.exists() else \"MISSING\"\n",
    "    print(f\"  [{status}] {fig_name}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Dashboard Architecture\n",
    "\n",
    "### Layout Structure\n",
    "\n",
    "```\n",
    "+------------------+---------------------------------------------+\n",
    "| SIDEBAR          | MAIN AREA                                   |\n",
    "|                  |                                             |\n",
    "| BAFS             | [Tab 1] Executive Summary                   |\n",
    "| Banking Anti-    |   - KPI cards (4 metrics)                   |\n",
    "| Fraud System     |   - Performance table + risk distribution   |\n",
    "|                  |   - Cost analysis                           |\n",
    "| -----------      |                                             |\n",
    "| Navigation       | [Tab 2] Model Performance                   |\n",
    "|  o Exec Summary  |   - Confusion matrix with cost overlay      |\n",
    "|  o Model Perf    |   - ROC curve + PR curve                    |\n",
    "|  o Case Studies  |   - Feature importance (SHAP)               |\n",
    "|  o Compliance    |   - Cost-benefit table by threshold         |\n",
    "|                  |                                             |\n",
    "| -----------      | [Tab 3] Case Study Explorer                 |\n",
    "| Global Filters   |   - 6 case studies with SHAP explanations   |\n",
    "|  Threshold: 0.41 |   - Plain-English model decisions           |\n",
    "|  Sample size: All|                                             |\n",
    "|                  | [Tab 4] Regulatory Compliance               |\n",
    "| -----------      |   - SR 11-7 checklist                       |\n",
    "| About & Methods  |   - Fair lending review                     |\n",
    "|  (expandable)    |   - Model governance framework              |\n",
    "|                  |   - Right-to-explanation + audit trail       |\n",
    "|                  |                                             |\n",
    "|                  | [FOOTER on every tab]                       |\n",
    "+------------------+---------------------------------------------+\n",
    "```\n",
    "\n",
    "### File Dependencies\n",
    "\n",
    "| File | Path (from `notebooks/dashboard/`) | Purpose |\n",
    "|------|--------------------------------------|--------|\n",
    "| XGBoost model | `../../models/xgboost_final.pkl` | Fraud scoring |\n",
    "| Scaler | `../../models/scaler.pkl` | Feature scaling |\n",
    "| Threshold config | `../../models/threshold_config.pkl` | Decision thresholds |\n",
    "| Test data | `../../data/processed/test.csv` | 118,108 transactions |\n",
    "| SHAP figures | `../../figures/shap/*.png` | Explainability plots |\n",
    "\n",
    "### Design Principles\n",
    "\n",
    "- **Professional banking aesthetic**: Blues, grays, no emojis\n",
    "- **Interactive filters**: Threshold slider + sample size selector\n",
    "- **Responsive layout**: `st.columns()` for side-by-side content\n",
    "- **Cost-sensitive framing**: Every metric tied to business impact ($75 FN, $10 FP)\n",
    "- **Regulatory awareness**: SR 11-7 compliance documented throughout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Streamlit Application\n",
    "\n",
    "The complete dashboard application is written to `dashboard_app.py` using the `%%writefile` magic command. When this notebook is executed, it creates (or overwrites) the app file in the current directory.\n",
    "\n",
    "**Key Streamlit configuration:**\n",
    "- `st.set_page_config(layout=\"wide\")` -- uses full browser width\n",
    "- `@st.cache_resource` -- caches the model (loaded once, shared across sessions)\n",
    "- `@st.cache_data` -- caches data and predictions (recomputed only when inputs change)\n",
    "- Custom CSS for banking color scheme (blues/grays)\n",
    "- `render_footer()` called at the bottom of every tab\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "%%writefile dashboard_app.py\n",
    "\"\"\"\n",
    "BAFS - Banking Anti-Fraud System\n",
    "Streamlit Dashboard Prototype\n",
    "\n",
    "Phase 5: Interactive Model Explainability & Regulatory Dashboard\n",
    "\n",
    "Run with:\n",
    "    cd notebooks/dashboard\n",
    "    streamlit run dashboard_app.py\n",
    "\"\"\"\n",
    "\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "from PIL import Image\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, precision_recall_curve, roc_curve, auc,\n",
    "    precision_score, recall_score, roc_auc_score\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "# Page Configuration\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "st.set_page_config(\n",
    "    page_title=\"BAFS - Banking Anti-Fraud System\",\n",
    "    page_icon=\":shield:\",\n",
    "    layout=\"wide\",\n",
    "    initial_sidebar_state=\"expanded\"\n",
    ")\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "# Custom CSS - Professional Banking Aesthetic\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "st.markdown(\"\"\"\n",
    "<style>\n",
    "    .main { background-color: #f8f9fa; }\n",
    "    h1, h2, h3 { color: #1a365d; }\n",
    "    .footer {\n",
    "        text-align: center;\n",
    "        color: #6c757d;\n",
    "        font-size: 0.85rem;\n",
    "        padding: 20px 0;\n",
    "        border-top: 1px solid #dee2e6;\n",
    "        margin-top: 40px;\n",
    "    }\n",
    "    .footer a { color: #1a365d; text-decoration: none; }\n",
    "    .footer a:hover { text-decoration: underline; }\n",
    "</style>\n",
    "\"\"\", unsafe_allow_html=True)\n",
    "\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "# Paths (relative to notebooks/dashboard/)\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "try:\n",
    "    BASE_PATH = Path(__file__).parent.resolve()\n",
    "except NameError:\n",
    "    BASE_PATH = Path.cwd()\n",
    "\n",
    "MODEL_PATH = BASE_PATH / '..' / '..' / 'models'\n",
    "DATA_PATH = BASE_PATH / '..' / '..' / 'data' / 'processed'\n",
    "FIGURES_PATH = BASE_PATH / '..' / '..' / 'figures' / 'shap'\n",
    "\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "# Data & Model Loading (cached for performance)\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "@st.cache_resource\n",
    "def load_model_artifacts():\n",
    "    \"\"\"Load XGBoost model, scaler, and threshold configuration.\"\"\"\n",
    "    model = joblib.load(MODEL_PATH / 'xgboost_final.pkl')\n",
    "    scaler = joblib.load(MODEL_PATH / 'scaler.pkl')\n",
    "    threshold_config = joblib.load(MODEL_PATH / 'threshold_config.pkl')\n",
    "    return model, scaler, threshold_config\n",
    "\n",
    "\n",
    "@st.cache_data\n",
    "def load_test_data():\n",
    "    \"\"\"Load the held-out test set (most recent transactions).\"\"\"\n",
    "    return pd.read_csv(DATA_PATH / 'test.csv')\n",
    "\n",
    "\n",
    "@st.cache_data\n",
    "def compute_predictions(_model, df, features):\n",
    "    \"\"\"Generate fraud scores for all test transactions.\"\"\"\n",
    "    X = df[features].copy()\n",
    "    X = X.replace([np.inf, -np.inf], [10, -10]).fillna(0)\n",
    "    y_true = df['isFraud'].values\n",
    "    y_scores = _model.predict_proba(X)[:, 1]\n",
    "    return X, y_true, y_scores\n",
    "\n",
    "\n",
    "# Load everything\n",
    "try:\n",
    "    model, scaler, threshold_config = load_model_artifacts()\n",
    "    df_test = load_test_data()\n",
    "\n",
    "    FEATURES = threshold_config['features']\n",
    "    AUTO_BLOCK = threshold_config['auto_block_threshold']\n",
    "    MANUAL_REVIEW = threshold_config['manual_review_threshold']\n",
    "    FN_COST = threshold_config.get('fn_cost', 75.0)\n",
    "    FP_COST = threshold_config.get('fp_cost', 10.0)\n",
    "\n",
    "    X_test, y_test, fraud_scores = compute_predictions(model, df_test, FEATURES)\n",
    "except Exception as e:\n",
    "    st.error(f\"Failed to load model or data: {e}\")\n",
    "    st.info(\n",
    "        \"Ensure model artifacts exist in ../../models/ \"\n",
    "        \"and test data in ../../data/processed/\"\n",
    "    )\n",
    "    st.stop()\n",
    "\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "# Banking-Friendly Feature Labels\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "FEATURE_LABELS = {\n",
    "    'txn_count_1hr': 'Transaction Velocity (1 hour)',\n",
    "    'txn_count_24hr': 'Transaction Velocity (24 hours)',\n",
    "    'amount_deviation': 'Spending Anomaly Score',\n",
    "    'is_first_transaction': 'First-Time Transaction',\n",
    "    'hour_of_day': 'Time of Day',\n",
    "    'is_weekend': 'Weekend Transaction',\n",
    "    'TransactionAmt': 'Transaction Amount ($)'\n",
    "}\n",
    "\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "# Reusable Footer (appears at the bottom of EVERY tab)\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "FOOTER_HTML = \"\"\"\n",
    "<div class=\"footer\">\n",
    "    <strong>BAFS - Banking Anti-Fraud System</strong><br>\n",
    "    <a href=\"https://github.com/JuanCRuizA/Agent-Fraud-Sentinel.git\"\n",
    "       target=\"_blank\">\n",
    "        https://github.com/JuanCRuizA/Agent-Fraud-Sentinel.git\n",
    "    </a><br>\n",
    "    Developed by Juan Carlos Ruiz Arteaga<br>\n",
    "    Banking Data Scientist<br>\n",
    "    MSc in Data Science &amp; AI, University of Liverpool<br>\n",
    "    Contact: j.ruiz-arteaga@liverpool.ac.uk\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def render_footer():\n",
    "    \"\"\"Render the standard project footer.\"\"\"\n",
    "    st.markdown(\"---\")\n",
    "    st.markdown(FOOTER_HTML, unsafe_allow_html=True)\n",
    "\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "# Sidebar\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "with st.sidebar:\n",
    "    st.title(\"BAFS\")\n",
    "    st.caption(\"Banking Anti-Fraud System\")\n",
    "    st.markdown(\"---\")\n",
    "\n",
    "    page = st.radio(\n",
    "        \"Navigation\",\n",
    "        [\n",
    "            \"Executive Summary\",\n",
    "            \"Model Performance\",\n",
    "            \"Case Study Explorer\",\n",
    "            \"Regulatory Compliance\",\n",
    "        ],\n",
    "        index=0,\n",
    "    )\n",
    "\n",
    "    st.markdown(\"---\")\n",
    "    st.subheader(\"Global Filters\")\n",
    "\n",
    "    risk_threshold = st.slider(\n",
    "        \"Risk Threshold\",\n",
    "        min_value=0.0,\n",
    "        max_value=1.0,\n",
    "        value=float(round(MANUAL_REVIEW, 2)),\n",
    "        step=0.01,\n",
    "        help=\"Transactions scoring above this threshold are flagged for review.\",\n",
    "    )\n",
    "\n",
    "    sample_size = st.selectbox(\n",
    "        \"Sample Size\",\n",
    "        options=[1000, 5000, 10000, 50000, len(y_test)],\n",
    "        index=4,\n",
    "        format_func=lambda x: (\n",
    "            f\"{x:,} transactions\"\n",
    "            if x < len(y_test)\n",
    "            else f\"Full dataset ({len(y_test):,})\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    st.markdown(\"---\")\n",
    "\n",
    "    with st.expander(\"About & Methods\"):\n",
    "        st.markdown(\n",
    "            \"- **Dataset:** IEEE-CIS Fraud Detection (590,540 transactions)\\n\"\n",
    "            \"- **Model:** XGBoost with cost-sensitive optimization\\n\"\n",
    "            \"- **Cost structure:** $75 FN / $10 FP (ratio 7.5 : 1)\\n\"\n",
    "            \"- **Explainability:** SHAP TreeExplainer\\n\"\n",
    "            \"- **Compliance:** Aligned with Federal Reserve SR 11-7\"\n",
    "        )\n",
    "\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "# Apply Global Filters\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "if sample_size < len(y_test):\n",
    "    np.random.seed(42)\n",
    "    idx = np.random.choice(len(y_test), size=sample_size, replace=False)\n",
    "    y_filt = y_test[idx]\n",
    "    scores_filt = fraud_scores[idx]\n",
    "    X_filt = X_test.iloc[idx]\n",
    "else:\n",
    "    y_filt = y_test\n",
    "    scores_filt = fraud_scores\n",
    "    X_filt = X_test\n",
    "\n",
    "y_pred_filt = (scores_filt >= risk_threshold).astype(int)\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "#  PAGE CONTENT\n",
    "# =====================================================================\n",
    "\n",
    "# ── TAB 1: Executive Summary ────────────────────────────────────────\n",
    "if page == \"Executive Summary\":\n",
    "    st.header(\"Executive Summary\")\n",
    "    st.caption(\n",
    "        \"Key performance indicators for the BAFS fraud detection system\"\n",
    "    )\n",
    "\n",
    "    # Compute KPIs\n",
    "    tp = int(((y_filt == 1) & (y_pred_filt == 1)).sum())\n",
    "    fp = int(((y_filt == 0) & (y_pred_filt == 1)).sum())\n",
    "    fn = int(((y_filt == 1) & (y_pred_filt == 0)).sum())\n",
    "    tn = int(((y_filt == 0) & (y_pred_filt == 0)).sum())\n",
    "    total_fraud = int(y_filt.sum())\n",
    "    recall = tp / total_fraud if total_fraud > 0 else 0\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "    fraud_prevented = tp * FN_COST\n",
    "    missed_fraud = fn * FN_COST\n",
    "    review_cost = fp * FP_COST\n",
    "    total_cost = missed_fraud + review_cost\n",
    "\n",
    "    # KPI cards\n",
    "    k1, k2, k3, k4 = st.columns(4)\n",
    "    k1.metric(\n",
    "        \"Fraud Detected\",\n",
    "        f\"{tp:,} / {total_fraud:,}\",\n",
    "        f\"{recall:.1%} recall\",\n",
    "    )\n",
    "    k2.metric(\n",
    "        \"False Positive Rate\",\n",
    "        f\"{fpr:.1%}\",\n",
    "        f\"{fp:,} false alarms\",\n",
    "    )\n",
    "    k3.metric(\n",
    "        \"Fraud Prevented\",\n",
    "        f\"${fraud_prevented:,.0f}\",\n",
    "        f\"{tp:,} transactions blocked\",\n",
    "    )\n",
    "    k4.metric(\n",
    "        \"Total Operational Cost\",\n",
    "        f\"${total_cost:,.0f}\",\n",
    "        f\"${total_cost / len(y_filt):.2f} per txn\",\n",
    "    )\n",
    "\n",
    "    st.markdown(\"---\")\n",
    "\n",
    "    # Two-column: performance table + risk distribution\n",
    "    left, right = st.columns(2)\n",
    "\n",
    "    with left:\n",
    "        st.subheader(\"Performance at Current Threshold\")\n",
    "        f1 = (\n",
    "            2 * precision * recall / (precision + recall)\n",
    "            if (precision + recall) > 0\n",
    "            else 0\n",
    "        )\n",
    "        perf_df = pd.DataFrame(\n",
    "            {\n",
    "                \"Metric\": [\n",
    "                    \"Recall (Fraud Detection Rate)\",\n",
    "                    \"Precision (Confirmation Rate)\",\n",
    "                    \"F1-Score\",\n",
    "                    \"False Positive Rate\",\n",
    "                    \"Threshold Applied\",\n",
    "                ],\n",
    "                \"Value\": [\n",
    "                    f\"{recall:.2%}\",\n",
    "                    f\"{precision:.2%}\",\n",
    "                    f\"{f1:.4f}\",\n",
    "                    f\"{fpr:.2%}\",\n",
    "                    f\"{risk_threshold:.3f}\",\n",
    "                ],\n",
    "            }\n",
    "        )\n",
    "        st.table(perf_df)\n",
    "\n",
    "    with right:\n",
    "        st.subheader(\"Risk Score Distribution\")\n",
    "        fig, ax = plt.subplots(figsize=(8, 5))\n",
    "        ax.hist(\n",
    "            scores_filt[y_filt == 0], bins=50, alpha=0.6,\n",
    "            color=\"#2196F3\", label=\"Legitimate\", density=True,\n",
    "        )\n",
    "        ax.hist(\n",
    "            scores_filt[y_filt == 1], bins=50, alpha=0.6,\n",
    "            color=\"#f44336\", label=\"Fraud\", density=True,\n",
    "        )\n",
    "        ax.axvline(\n",
    "            risk_threshold, color=\"#333\", linestyle=\"--\",\n",
    "            linewidth=2, label=f\"Threshold ({risk_threshold:.2f})\",\n",
    "        )\n",
    "        ax.set_xlabel(\"Fraud Score\", fontsize=12)\n",
    "        ax.set_ylabel(\"Density\", fontsize=12)\n",
    "        ax.set_title(\n",
    "            \"Distribution of Fraud Scores\",\n",
    "            fontsize=14, fontweight=\"bold\",\n",
    "        )\n",
    "        ax.legend(fontsize=10)\n",
    "        ax.grid(alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        st.pyplot(fig)\n",
    "        plt.close()\n",
    "\n",
    "    # Cost breakdown\n",
    "    st.subheader(\"Cost Analysis\")\n",
    "    c1, c2, c3 = st.columns(3)\n",
    "    c1.metric(\n",
    "        \"Missed Fraud Cost\",\n",
    "        f\"${missed_fraud:,.0f}\",\n",
    "        f\"{fn:,} missed x ${FN_COST:.0f}\",\n",
    "    )\n",
    "    c2.metric(\n",
    "        \"False Alarm Cost\",\n",
    "        f\"${review_cost:,.0f}\",\n",
    "        f\"{fp:,} reviews x ${FP_COST:.0f}\",\n",
    "    )\n",
    "    no_model = total_fraud * FN_COST\n",
    "    savings = no_model - missed_fraud\n",
    "    c3.metric(\n",
    "        \"Fraud Savings vs No Model\",\n",
    "        f\"${savings:,.0f}\",\n",
    "        f\"${no_model:,.0f} baseline\",\n",
    "    )\n",
    "\n",
    "    render_footer()\n",
    "\n",
    "\n",
    "# ── TAB 2: Model Performance ────────────────────────────────────────\n",
    "elif page == \"Model Performance\":\n",
    "    st.header(\"Model Performance Analysis\")\n",
    "    st.caption(\n",
    "        \"Detailed evaluation of the XGBoost fraud detection model\"\n",
    "    )\n",
    "\n",
    "    # Compute confusion matrix values for this page\n",
    "    cm = confusion_matrix(y_filt, y_pred_filt)\n",
    "    tn_v, fp_v, fn_v, tp_v = cm.ravel()\n",
    "\n",
    "    # Row 1: Confusion Matrix + ROC\n",
    "    r1c1, r1c2 = st.columns(2)\n",
    "\n",
    "    with r1c1:\n",
    "        st.subheader(\"Confusion Matrix with Cost Overlay\")\n",
    "        labels = np.array(\n",
    "            [\n",
    "                [\n",
    "                    f\"TN\\n{tn_v:,}\\n$0\",\n",
    "                    f\"FP\\n{fp_v:,}\\n${fp_v * FP_COST:,.0f}\",\n",
    "                ],\n",
    "                [\n",
    "                    f\"FN\\n{fn_v:,}\\n${fn_v * FN_COST:,.0f}\",\n",
    "                    f\"TP\\n{tp_v:,}\\nPrevented\",\n",
    "                ],\n",
    "            ]\n",
    "        )\n",
    "        fig, ax = plt.subplots(figsize=(7, 6))\n",
    "        sns.heatmap(\n",
    "            cm, annot=labels, fmt=\"\", cmap=\"Blues\", ax=ax,\n",
    "            xticklabels=[\"Predicted Legit\", \"Predicted Fraud\"],\n",
    "            yticklabels=[\"Actual Legit\", \"Actual Fraud\"],\n",
    "            cbar_kws={\"label\": \"Count\"},\n",
    "        )\n",
    "        ax.set_title(\n",
    "            f\"Confusion Matrix (threshold = {risk_threshold:.3f})\",\n",
    "            fontsize=13, fontweight=\"bold\",\n",
    "        )\n",
    "        plt.tight_layout()\n",
    "        st.pyplot(fig)\n",
    "        plt.close()\n",
    "\n",
    "    with r1c2:\n",
    "        st.subheader(\"ROC Curve\")\n",
    "        fpr_c, tpr_c, _ = roc_curve(y_filt, scores_filt)\n",
    "        roc_auc_val = roc_auc_score(y_filt, scores_filt)\n",
    "\n",
    "        # Operating point at current threshold\n",
    "        tpr_op = recall_score(y_filt, y_pred_filt)\n",
    "        fpr_op = fp_v / (fp_v + tn_v) if (fp_v + tn_v) > 0 else 0\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(7, 6))\n",
    "        ax.plot(\n",
    "            fpr_c, tpr_c, color=\"#1565C0\", linewidth=2,\n",
    "            label=f\"XGBoost (AUC = {roc_auc_val:.4f})\",\n",
    "        )\n",
    "        ax.plot([0, 1], [0, 1], \"k--\", alpha=0.3, label=\"Random\")\n",
    "        ax.scatter(\n",
    "            [fpr_op], [tpr_op], color=\"red\", s=100, zorder=5,\n",
    "            label=f\"Operating Point ({risk_threshold:.2f})\",\n",
    "        )\n",
    "        ax.set_xlabel(\"False Positive Rate\", fontsize=12)\n",
    "        ax.set_ylabel(\"True Positive Rate (Recall)\", fontsize=12)\n",
    "        ax.set_title(\"ROC Curve\", fontsize=13, fontweight=\"bold\")\n",
    "        ax.legend(fontsize=10, loc=\"lower right\")\n",
    "        ax.grid(alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        st.pyplot(fig)\n",
    "        plt.close()\n",
    "\n",
    "    # Row 2: PR Curve + Feature Importance\n",
    "    r2c1, r2c2 = st.columns(2)\n",
    "\n",
    "    with r2c1:\n",
    "        st.subheader(\"Precision-Recall Curve\")\n",
    "        prec_c, rec_c, _ = precision_recall_curve(y_filt, scores_filt)\n",
    "        pr_auc_val = auc(rec_c, prec_c)\n",
    "\n",
    "        prec_op = (\n",
    "            precision_score(y_filt, y_pred_filt)\n",
    "            if y_pred_filt.sum() > 0 else 0\n",
    "        )\n",
    "        rec_op = (\n",
    "            recall_score(y_filt, y_pred_filt)\n",
    "            if y_filt.sum() > 0 else 0\n",
    "        )\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(7, 6))\n",
    "        ax.plot(\n",
    "            rec_c, prec_c, color=\"#1565C0\", linewidth=2,\n",
    "            label=f\"XGBoost (PR-AUC = {pr_auc_val:.4f})\",\n",
    "        )\n",
    "        ax.axhline(\n",
    "            y=y_filt.mean(), color=\"red\", linestyle=\"--\",\n",
    "            alpha=0.5, label=f\"Baseline ({y_filt.mean():.4f})\",\n",
    "        )\n",
    "        ax.scatter(\n",
    "            [rec_op], [prec_op], color=\"red\", s=100, zorder=5,\n",
    "            label=f\"Operating Point ({risk_threshold:.2f})\",\n",
    "        )\n",
    "        ax.set_xlabel(\"Recall\", fontsize=12)\n",
    "        ax.set_ylabel(\"Precision\", fontsize=12)\n",
    "        ax.set_title(\n",
    "            \"Precision-Recall Curve\", fontsize=13, fontweight=\"bold\",\n",
    "        )\n",
    "        ax.legend(fontsize=10)\n",
    "        ax.grid(alpha=0.3)\n",
    "        ax.set_xlim([0, 1.05])\n",
    "        plt.tight_layout()\n",
    "        st.pyplot(fig)\n",
    "        plt.close()\n",
    "\n",
    "    with r2c2:\n",
    "        st.subheader(\"Feature Importance (Top 7)\")\n",
    "        shap_img = FIGURES_PATH / \"shap_feature_importance_bar.png\"\n",
    "        if shap_img.exists():\n",
    "            st.image(\n",
    "                Image.open(shap_img), use_container_width=True,\n",
    "            )\n",
    "        else:\n",
    "            # Fallback: use model's built-in feature importances\n",
    "            importance = model.feature_importances_\n",
    "            imp_df = pd.DataFrame(\n",
    "                {\n",
    "                    \"Feature\": [\n",
    "                        FEATURE_LABELS.get(f, f) for f in FEATURES\n",
    "                    ],\n",
    "                    \"Importance\": importance,\n",
    "                }\n",
    "            ).sort_values(\"Importance\", ascending=True)\n",
    "            fig, ax = plt.subplots(figsize=(7, 5))\n",
    "            ax.barh(\n",
    "                imp_df[\"Feature\"], imp_df[\"Importance\"],\n",
    "                color=\"steelblue\",\n",
    "            )\n",
    "            ax.set_xlabel(\"Importance (Gain)\", fontsize=11)\n",
    "            ax.set_title(\n",
    "                \"Feature Importance\", fontsize=13, fontweight=\"bold\",\n",
    "            )\n",
    "            plt.tight_layout()\n",
    "            st.pyplot(fig)\n",
    "            plt.close()\n",
    "\n",
    "    # Cost-Benefit Analysis Table\n",
    "    st.subheader(\"Cost-Benefit Analysis by Threshold\")\n",
    "    thresholds = sorted(\n",
    "        set(\n",
    "            [0.20, 0.30, round(MANUAL_REVIEW, 2), 0.50,\n",
    "             0.60, 0.70, 0.80, round(AUTO_BLOCK, 2)]\n",
    "        )\n",
    "    )\n",
    "    rows = []\n",
    "    for t in thresholds:\n",
    "        yp = (scores_filt >= t).astype(int)\n",
    "        t_tp = int(((y_filt == 1) & (yp == 1)).sum())\n",
    "        t_fp = int(((y_filt == 0) & (yp == 1)).sum())\n",
    "        t_fn = int(((y_filt == 1) & (yp == 0)).sum())\n",
    "        t_rec = t_tp / y_filt.sum() if y_filt.sum() > 0 else 0\n",
    "        t_pre = t_tp / (t_tp + t_fp) if (t_tp + t_fp) > 0 else 0\n",
    "        t_cost = t_fn * FN_COST + t_fp * FP_COST\n",
    "        marker = \" *\" if abs(t - risk_threshold) < 0.005 else \"\"\n",
    "        rows.append(\n",
    "            {\n",
    "                \"Threshold\": f\"{t:.2f}{marker}\",\n",
    "                \"Recall\": f\"{t_rec:.1%}\",\n",
    "                \"Precision\": f\"{t_pre:.1%}\",\n",
    "                \"True Positives\": f\"{t_tp:,}\",\n",
    "                \"False Positives\": f\"{t_fp:,}\",\n",
    "                \"Missed Frauds\": f\"{t_fn:,}\",\n",
    "                \"Total Cost\": f\"${t_cost:,.0f}\",\n",
    "            }\n",
    "        )\n",
    "    st.caption(\"* = current threshold\")\n",
    "    st.dataframe(\n",
    "        pd.DataFrame(rows), use_container_width=True, hide_index=True,\n",
    "    )\n",
    "\n",
    "    render_footer()\n",
    "\n",
    "\n",
    "# ── TAB 3: Case Study Explorer ──────────────────────────────────────\n",
    "elif page == \"Case Study Explorer\":\n",
    "    st.header(\"Case Study Explorer\")\n",
    "    st.caption(\n",
    "        \"Detailed analysis of individual transaction decisions \"\n",
    "        \"with SHAP explanations\"\n",
    "    )\n",
    "\n",
    "    # Case study definitions (from Phase 4 SHAP analysis)\n",
    "    cases = {\n",
    "        \"Case 1: True Positive -- Clear Fraud Caught\": {\n",
    "            \"score\": 0.9094,\n",
    "            \"actual\": \"FRAUD\",\n",
    "            \"decision\": \"AUTO-BLOCK\",\n",
    "            \"features\": {\n",
    "                \"Transaction Amount\": \"$17.52\",\n",
    "                \"Time of Day\": \"6:00 AM\",\n",
    "                \"Transactions (1 hour)\": \"1\",\n",
    "                \"Transactions (24 hours)\": \"9\",\n",
    "                \"Weekend\": \"Yes\",\n",
    "                \"Spending Anomaly\": \"-0.39 std devs\",\n",
    "                \"First Transaction\": \"No\",\n",
    "            },\n",
    "            \"explanation\": (\n",
    "                \"This transaction was correctly identified as fraud. \"\n",
    "                \"Multiple strong indicators were present: high daily \"\n",
    "                \"velocity (9 transactions in 24 hours), weekend timing, \"\n",
    "                \"and a small transaction amount typical of card-testing \"\n",
    "                \"behaviour. The model automatically blocked this \"\n",
    "                \"transaction, preventing potential fraud loss.\"\n",
    "            ),\n",
    "            \"drivers\": [\n",
    "                \"High 24-hour velocity (9 transactions)\",\n",
    "                \"Weekend + early morning timing\",\n",
    "                \"Small amount consistent with card testing\",\n",
    "            ],\n",
    "        },\n",
    "        \"Case 2: True Positive -- Velocity-Driven Detection\": {\n",
    "            \"score\": 0.7332,\n",
    "            \"actual\": \"FRAUD\",\n",
    "            \"decision\": \"MANUAL REVIEW\",\n",
    "            \"features\": {\n",
    "                \"Transaction Amount\": \"$59.64\",\n",
    "                \"Time of Day\": \"4:00 AM\",\n",
    "                \"Transactions (1 hour)\": \"1\",\n",
    "                \"Transactions (24 hours)\": \"3\",\n",
    "                \"Weekend\": \"No\",\n",
    "                \"Spending Anomaly\": \"+0.54 std devs\",\n",
    "                \"First Transaction\": \"No\",\n",
    "            },\n",
    "            \"explanation\": (\n",
    "                \"This fraud was detected primarily through velocity \"\n",
    "                \"signals. The combination of elevated 24-hour velocity, \"\n",
    "                \"early morning timing, and above-average spending \"\n",
    "                \"deviation pushed the score into the manual review zone. \"\n",
    "                \"An analyst would confirm this as fraud based on the \"\n",
    "                \"pattern.\"\n",
    "            ),\n",
    "            \"drivers\": [\n",
    "                \"Velocity features elevated\",\n",
    "                \"4 AM transaction time\",\n",
    "                \"Above-average spending deviation\",\n",
    "            ],\n",
    "        },\n",
    "        \"Case 3: False Negative -- Missed Fraud\": {\n",
    "            \"score\": 0.0853,\n",
    "            \"actual\": \"FRAUD\",\n",
    "            \"decision\": \"AUTO-APPROVE\",\n",
    "            \"features\": {\n",
    "                \"Transaction Amount\": \"$57.95\",\n",
    "                \"Time of Day\": \"Business hours\",\n",
    "                \"Transactions (1 hour)\": \"0\",\n",
    "                \"Transactions (24 hours)\": \"0\",\n",
    "                \"Weekend\": \"No\",\n",
    "                \"Spending Anomaly\": \"-1.50 std devs\",\n",
    "                \"First Transaction\": \"Yes\",\n",
    "            },\n",
    "            \"explanation\": (\n",
    "                \"The model failed to detect this fraud because all \"\n",
    "                \"behavioural features appeared normal. The transaction \"\n",
    "                \"had zero velocity (isolated event), a moderate amount, \"\n",
    "                \"and occurred during business hours. This represents a \"\n",
    "                \"model limitation: sophisticated fraudsters who pace \"\n",
    "                \"transactions can evade velocity-based detection.\"\n",
    "            ),\n",
    "            \"drivers\": [\n",
    "                \"Zero velocity (no pattern to detect)\",\n",
    "                \"Normal business hours\",\n",
    "                \"First transaction (no history)\",\n",
    "            ],\n",
    "            \"improvement\": (\n",
    "                \"Consider adding merchant-category features and device \"\n",
    "                \"fingerprinting to catch isolated sophisticated fraud.\"\n",
    "            ),\n",
    "        },\n",
    "        \"Case 4: False Positive -- Legitimate Flagged\": {\n",
    "            \"score\": 0.9342,\n",
    "            \"actual\": \"LEGITIMATE\",\n",
    "            \"decision\": \"AUTO-BLOCK\",\n",
    "            \"features\": {\n",
    "                \"Transaction Amount\": \"$15.00\",\n",
    "                \"Time of Day\": \"9:00 AM\",\n",
    "                \"Transactions (1 hour)\": \"1\",\n",
    "                \"Transactions (24 hours)\": \"2\",\n",
    "                \"Weekend\": \"Yes\",\n",
    "                \"Spending Anomaly\": \"-0.26 std devs\",\n",
    "                \"First Transaction\": \"No\",\n",
    "            },\n",
    "            \"explanation\": (\n",
    "                \"This legitimate transaction was incorrectly blocked. \"\n",
    "                \"The model was triggered by the combination of weekend \"\n",
    "                \"timing, low amount (similar to card-testing), and \"\n",
    "                \"moderate velocity. This false positive demonstrates \"\n",
    "                \"why human review and dispute resolution processes are \"\n",
    "                \"essential.\"\n",
    "            ),\n",
    "            \"drivers\": [\n",
    "                \"Weekend + morning timing\",\n",
    "                \"Small amount triggered card-testing pattern\",\n",
    "                \"Multiple moderate risk factors accumulated\",\n",
    "            ],\n",
    "        },\n",
    "        \"Case 5: Auto-Block Candidate -- High Confidence\": {\n",
    "            \"score\": 0.9342,\n",
    "            \"actual\": \"LEGITIMATE\",\n",
    "            \"decision\": \"AUTO-BLOCK\",\n",
    "            \"features\": {\n",
    "                \"Transaction Amount\": \"$15.00\",\n",
    "                \"Time of Day\": \"9:00 AM\",\n",
    "                \"Transactions (1 hour)\": \"1\",\n",
    "                \"Transactions (24 hours)\": \"2\",\n",
    "                \"Weekend\": \"Yes\",\n",
    "                \"Spending Anomaly\": \"-0.26 std devs\",\n",
    "                \"First Transaction\": \"No\",\n",
    "            },\n",
    "            \"explanation\": (\n",
    "                \"This case illustrates the risk of auto-blocking: a \"\n",
    "                \"high-confidence score (0.93) on a legitimate \"\n",
    "                \"transaction. While rare, auto-block false positives \"\n",
    "                \"highlight the need for rapid dispute resolution and \"\n",
    "                \"continuous model monitoring. The SHAP explanation \"\n",
    "                \"provides the audit trail needed for customer \"\n",
    "                \"communication.\"\n",
    "            ),\n",
    "            \"drivers\": [\n",
    "                \"Score exceeded auto-block threshold (0.90)\",\n",
    "                \"Pattern matched card-testing signature\",\n",
    "                \"Demonstrates need for dispute resolution workflow\",\n",
    "            ],\n",
    "        },\n",
    "        \"Case 6: Borderline -- Near Review Threshold\": {\n",
    "            \"score\": 0.3648,\n",
    "            \"actual\": \"LEGITIMATE\",\n",
    "            \"decision\": \"AUTO-APPROVE\",\n",
    "            \"features\": {\n",
    "                \"Transaction Amount\": \"$125.00\",\n",
    "                \"Time of Day\": \"Afternoon\",\n",
    "                \"Transactions (1 hour)\": \"0\",\n",
    "                \"Transactions (24 hours)\": \"0\",\n",
    "                \"Weekend\": \"No\",\n",
    "                \"Spending Anomaly\": \"Normal\",\n",
    "                \"First Transaction\": \"No\",\n",
    "            },\n",
    "            \"explanation\": (\n",
    "                \"This borderline case scored just below the manual \"\n",
    "                \"review threshold (0.41). The transaction had no \"\n",
    "                \"velocity flags and a reasonable amount. The model \"\n",
    "                \"correctly approved it, but the score shows it was \"\n",
    "                \"not far from the review zone. Small changes in \"\n",
    "                \"behaviour could tip similar transactions into review.\"\n",
    "            ),\n",
    "            \"drivers\": [\n",
    "                \"Score near but below threshold (0.36 vs 0.41)\",\n",
    "                \"No velocity anomalies\",\n",
    "                \"Normal transaction pattern with slight uncertainty\",\n",
    "            ],\n",
    "        },\n",
    "    }\n",
    "\n",
    "    selected = st.selectbox(\n",
    "        \"Select a case study to analyse:\", list(cases.keys()),\n",
    "    )\n",
    "    case = cases[selected]\n",
    "\n",
    "    st.markdown(\"---\")\n",
    "\n",
    "    # KPI row for selected case\n",
    "    m1, m2, m3 = st.columns(3)\n",
    "    m1.metric(\"Fraud Score\", f\"{case['score']:.4f}\")\n",
    "    m2.metric(\"Model Decision\", case[\"decision\"])\n",
    "    m3.metric(\"Actual Outcome\", case[\"actual\"])\n",
    "\n",
    "    # Feature details\n",
    "    st.subheader(\"Transaction Features\")\n",
    "    feat_items = list(case[\"features\"].items())\n",
    "    mid = (len(feat_items) + 1) // 2\n",
    "    fc1, fc2 = st.columns(2)\n",
    "    with fc1:\n",
    "        for k, v in feat_items[:mid]:\n",
    "            st.markdown(f\"**{k}:** {v}\")\n",
    "    with fc2:\n",
    "        for k, v in feat_items[mid:]:\n",
    "            st.markdown(f\"**{k}:** {v}\")\n",
    "\n",
    "    # SHAP waterfall plot\n",
    "    st.subheader(\"SHAP Explanation\")\n",
    "    waterfall = FIGURES_PATH / \"shap_waterfall_cases.png\"\n",
    "    if waterfall.exists():\n",
    "        st.image(\n",
    "            Image.open(waterfall),\n",
    "            caption=(\n",
    "                \"SHAP waterfall plots for all 6 case studies \"\n",
    "                \"(from Phase 4 analysis)\"\n",
    "            ),\n",
    "            use_container_width=True,\n",
    "        )\n",
    "    else:\n",
    "        st.info(\n",
    "            \"SHAP waterfall plot not available. \"\n",
    "            \"Run notebook 04_shap_explainability.ipynb first.\"\n",
    "        )\n",
    "\n",
    "    # Plain-English explanation\n",
    "    st.subheader(\"Model Decision Explanation\")\n",
    "    st.write(case[\"explanation\"])\n",
    "\n",
    "    st.subheader(\"Key Risk Drivers\")\n",
    "    for d in case[\"drivers\"]:\n",
    "        st.markdown(f\"- {d}\")\n",
    "\n",
    "    if \"improvement\" in case:\n",
    "        st.subheader(\"Recommended Improvement\")\n",
    "        st.write(case[\"improvement\"])\n",
    "\n",
    "    render_footer()\n",
    "\n",
    "\n",
    "# ── TAB 4: Regulatory Compliance ────────────────────────────────────\n",
    "elif page == \"Regulatory Compliance\":\n",
    "    st.header(\"Regulatory Compliance\")\n",
    "    st.caption(\n",
    "        \"Model governance, fair lending review, and audit readiness\"\n",
    "    )\n",
    "\n",
    "    # SR 11-7 Checklist\n",
    "    st.subheader(\"SR 11-7 Model Documentation Checklist\")\n",
    "\n",
    "    done_items = [\n",
    "        \"Model documentation (purpose, inputs, outputs, assumptions)\",\n",
    "        \"Performance metrics on held-out test data\",\n",
    "        \"Global explainability (feature importance, SHAP summary)\",\n",
    "        \"Local explainability (individual transaction SHAP)\",\n",
    "        \"Limitations and known risks documented\",\n",
    "        \"Fair lending feature review conducted\",\n",
    "        \"Right-to-explanation capability demonstrated\",\n",
    "        \"Audit trail requirements specified\",\n",
    "    ]\n",
    "    pending_items = [\n",
    "        \"Disparate impact testing (requires demographic data)\",\n",
    "        \"Champion/challenger framework\",\n",
    "        \"Ongoing monitoring dashboard (drift detection)\",\n",
    "        \"Quarterly model revalidation schedule\",\n",
    "    ]\n",
    "\n",
    "    chk1, chk2 = st.columns(2)\n",
    "    with chk1:\n",
    "        st.markdown(\"**Completed**\")\n",
    "        for item in done_items:\n",
    "            st.checkbox(item, value=True, disabled=True, key=f\"d_{item}\")\n",
    "    with chk2:\n",
    "        st.markdown(\"**Pending**\")\n",
    "        for item in pending_items:\n",
    "            st.checkbox(item, value=False, disabled=True, key=f\"p_{item}\")\n",
    "\n",
    "    st.markdown(\"---\")\n",
    "\n",
    "    # Fair Lending\n",
    "    st.subheader(\"Fair Lending Considerations\")\n",
    "\n",
    "    fl_data = pd.DataFrame(\n",
    "        [\n",
    "            {\n",
    "                \"Feature\": \"Transaction Velocity (1hr, 24hr)\",\n",
    "                \"Risk Level\": \"LOW\",\n",
    "                \"Assessment\": (\n",
    "                    \"Behavioural pattern. Monitor for disparate \"\n",
    "                    \"impact across segments.\"\n",
    "                ),\n",
    "            },\n",
    "            {\n",
    "                \"Feature\": \"Spending Anomaly Score\",\n",
    "                \"Risk Level\": \"LOW\",\n",
    "                \"Assessment\": (\n",
    "                    \"Self-norming (deviation from client's own \"\n",
    "                    \"history).\"\n",
    "                ),\n",
    "            },\n",
    "            {\n",
    "                \"Feature\": \"First-Time Transaction\",\n",
    "                \"Risk Level\": \"MEDIUM\",\n",
    "                \"Assessment\": (\n",
    "                    \"New customers disproportionately flagged. \"\n",
    "                    \"Monitor approval rates.\"\n",
    "                ),\n",
    "            },\n",
    "            {\n",
    "                \"Feature\": \"Time of Day / Weekend\",\n",
    "                \"Risk Level\": \"MEDIUM\",\n",
    "                \"Assessment\": (\n",
    "                    \"Shift workers and time zones may be affected. \"\n",
    "                    \"Monitor FPR by region.\"\n",
    "                ),\n",
    "            },\n",
    "            {\n",
    "                \"Feature\": \"Transaction Amount\",\n",
    "                \"Risk Level\": \"LOW-MEDIUM\",\n",
    "                \"Assessment\": (\n",
    "                    \"Spending power correlates with income. \"\n",
    "                    \"Monitor across segments.\"\n",
    "                ),\n",
    "            },\n",
    "        ]\n",
    "    )\n",
    "    st.dataframe(\n",
    "        fl_data, use_container_width=True, hide_index=True,\n",
    "    )\n",
    "    st.markdown(\n",
    "        \"**Overall Assessment:** No direct protected attributes used. \"\n",
    "        \"Conduct disparate impact analysis when demographic data \"\n",
    "        \"becomes available.\"\n",
    "    )\n",
    "\n",
    "    st.markdown(\"---\")\n",
    "\n",
    "    # Model Governance\n",
    "    st.subheader(\"Model Governance Framework\")\n",
    "\n",
    "    gov1, gov2 = st.columns(2)\n",
    "\n",
    "    with gov1:\n",
    "        st.markdown(\"**Model Identification**\")\n",
    "        st.text(\"Name:     Agent Fraud Sentinel (XGBoost)\")\n",
    "        st.text(\"Version:  1.0\")\n",
    "        st.text(\"Type:     Gradient Boosted Decision Tree\")\n",
    "        st.text(\"Purpose:  Real-time fraud detection\")\n",
    "        st.text(\"Date:     February 2026\")\n",
    "        st.text(\"\")\n",
    "        st.markdown(\"**Monitoring Schedule**\")\n",
    "        sched = pd.DataFrame(\n",
    "            [\n",
    "                {\n",
    "                    \"Frequency\": \"Daily\",\n",
    "                    \"Activity\": (\n",
    "                        \"Alert volume, auto-block count, queue size\"\n",
    "                    ),\n",
    "                },\n",
    "                {\n",
    "                    \"Frequency\": \"Weekly\",\n",
    "                    \"Activity\": (\n",
    "                        \"Recall, precision, FPR by risk tier\"\n",
    "                    ),\n",
    "                },\n",
    "                {\n",
    "                    \"Frequency\": \"Monthly\",\n",
    "                    \"Activity\": (\n",
    "                        \"SHAP drift analysis, feature stability\"\n",
    "                    ),\n",
    "                },\n",
    "                {\n",
    "                    \"Frequency\": \"Quarterly\",\n",
    "                    \"Activity\": (\n",
    "                        \"Full revalidation, threshold recalibration\"\n",
    "                    ),\n",
    "                },\n",
    "                {\n",
    "                    \"Frequency\": \"Annual\",\n",
    "                    \"Activity\": \"Comprehensive SR 11-7 review\",\n",
    "                },\n",
    "            ]\n",
    "        )\n",
    "        st.dataframe(\n",
    "            sched, use_container_width=True, hide_index=True,\n",
    "        )\n",
    "\n",
    "    with gov2:\n",
    "        st.markdown(\"**Model Risk Classification**\")\n",
    "        st.text(\"Recommended Tier:  Tier 2\")\n",
    "        st.text(\"Rationale:         Material financial impact\")\n",
    "        st.text(\"Review Cycle:      Quarterly\")\n",
    "        st.text(\"\")\n",
    "        st.markdown(\"**Key Assumptions**\")\n",
    "        st.markdown(\n",
    "            \"1. Training fraud patterns represent future fraud\\n\"\n",
    "            \"2. Temporal ordering preserved (no data leakage)\\n\"\n",
    "            \"3. Client identity: card1 + addr1 + P_emaildomain\\n\"\n",
    "            \"4. Cost ratio 7.5:1 ($75 FN, $10 FP)\\n\"\n",
    "            \"5. Minimum 75% recall target\"\n",
    "        )\n",
    "\n",
    "    st.markdown(\"---\")\n",
    "\n",
    "    # Right to Explanation\n",
    "    st.subheader(\"Right-to-Explanation Capabilities\")\n",
    "\n",
    "    st.markdown(\n",
    "        \"Customers whose transactions are blocked or flagged may \"\n",
    "        \"request an explanation. SHAP values provide a complete, \"\n",
    "        \"auditable explanation at the individual level.\\n\\n\"\n",
    "        \"**For any transaction, the system can generate:**\\n\\n\"\n",
    "        \"1. **Feature-level attribution** -- which factors \"\n",
    "        \"contributed to the decision\\n\"\n",
    "        \"2. **Quantified contribution** -- how much each factor \"\n",
    "        \"affected the score\\n\"\n",
    "        \"3. **Comparison to baseline** -- score relative to average \"\n",
    "        \"fraud probability\\n\\n\"\n",
    "        \"**Dispute Resolution Workflow:**\\n\\n\"\n",
    "        \"1. Customer contacts bank about blocked transaction\\n\"\n",
    "        \"2. Analyst retrieves SHAP explanation from audit log\\n\"\n",
    "        \"3. Analyst reviews feature contributions in plain English\\n\"\n",
    "        \"4. If false positive: approve transaction, note for model \"\n",
    "        \"feedback\\n\"\n",
    "        \"5. If true fraud: confirm block, initiate investigation\"\n",
    "    )\n",
    "\n",
    "    st.markdown(\"---\")\n",
    "\n",
    "    # Data Lineage\n",
    "    st.subheader(\"Data Lineage and Audit Trail\")\n",
    "\n",
    "    st.markdown(\n",
    "        \"**Data Source:** IEEE-CIS Fraud Detection Dataset \"\n",
    "        \"(590,540 transactions)\\n\\n\"\n",
    "        \"**Processing Pipeline:**\\n\\n\"\n",
    "        \"1. Raw data ingestion (434 features)\\n\"\n",
    "        \"2. Feature engineering: 7 behavioural features derived \"\n",
    "        \"from raw data\\n\"\n",
    "        \"3. Temporal split: 60/20/20 \"\n",
    "        \"(train / validation / test)\\n\"\n",
    "        \"4. Model training: XGBoost with cost-sensitive \"\n",
    "        \"optimization\\n\"\n",
    "        \"5. Threshold calibration: cost-minimising with 75% \"\n",
    "        \"recall constraint\\n\"\n",
    "        \"6. Explainability: SHAP TreeExplainer for all \"\n",
    "        \"predictions\\n\\n\"\n",
    "        \"**Audit Requirements:**\\n\\n\"\n",
    "        \"- SHAP values stored at scoring time\\n\"\n",
    "        \"- Retention: minimum 7 years (regulatory requirement)\\n\"\n",
    "        \"- Log fields: transaction_id, fraud_score, threshold, \"\n",
    "        \"decision, SHAP values, model_version, timestamp\"\n",
    "    )\n",
    "\n",
    "    render_footer()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Tab Design Documentation\n",
    "\n",
    "### Tab 1: Executive Summary\n",
    "\n",
    "**Purpose:** Provide at-a-glance KPIs for fraud operations leadership.\n",
    "\n",
    "**Components:**\n",
    "- **4 KPI cards** (top row): Fraud Detected, False Positive Rate, Fraud Prevented ($), Total Operational Cost\n",
    "- **Performance table** (left column): Recall, Precision, F1, FPR, and current threshold\n",
    "- **Risk score distribution** (right column): Overlapping histograms of fraud vs legitimate scores with threshold line\n",
    "- **Cost analysis** (bottom row): Missed fraud cost, false alarm cost, savings vs no-model baseline\n",
    "\n",
    "**Interactive elements:**\n",
    "- All metrics update dynamically when the user adjusts the sidebar threshold slider\n",
    "- Sample size selector allows zooming into subsets for faster exploration\n",
    "\n",
    "**Business value:** Executives can immediately see the trade-off between catching more fraud (lower threshold) and operational cost (more false alarms).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tab 2: Model Performance\n",
    "\n",
    "**Purpose:** Deep technical evaluation for model validators and data science teams.\n",
    "\n",
    "**Components:**\n",
    "- **Confusion matrix with cost overlay**: Each cell shows count AND dollar impact ($75 per missed fraud, $10 per false alarm)\n",
    "- **ROC curve**: With operating point marked at current threshold, showing trade-off between TPR and FPR\n",
    "- **Precision-Recall curve**: More informative than ROC for imbalanced data (3.44% fraud rate), with baseline marked\n",
    "- **Feature importance**: SHAP-based feature importance bar chart (loaded from Phase 4 output)\n",
    "- **Cost-benefit table**: Shows recall, precision, and total cost at 8 threshold values for comparison\n",
    "\n",
    "**Design decisions:**\n",
    "- 2x2 grid layout puts related charts side by side for easy comparison\n",
    "- Cost overlay on confusion matrix connects statistical metrics to business impact\n",
    "- Cost-benefit table enables threshold selection during production calibration meetings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tab 3: Case Study Explorer\n",
    "\n",
    "**Purpose:** Demonstrate individual transaction explainability for analysts and auditors.\n",
    "\n",
    "**6 Case Studies (from Phase 4 SHAP analysis):**\n",
    "\n",
    "| Case | Type | Score | Actual | Key Insight |\n",
    "|------|------|-------|--------|-------------|\n",
    "| 1 | True Positive (clear) | 0.9094 | Fraud | Multiple strong indicators, auto-blocked |\n",
    "| 2 | True Positive (velocity) | 0.7332 | Fraud | Velocity features drove detection |\n",
    "| 3 | False Negative | 0.0853 | Fraud | All features appeared normal, model limitation |\n",
    "| 4 | False Positive | 0.9342 | Legit | Card-testing pattern on legitimate purchase |\n",
    "| 5 | Auto-Block candidate | 0.9342 | Legit | High-confidence false alarm, dispute resolution |\n",
    "| 6 | Borderline | 0.3648 | Legit | Near threshold, demonstrates sensitivity |\n",
    "\n",
    "**For each case, the dashboard shows:**\n",
    "- Fraud score, model decision, and actual outcome\n",
    "- All 7 feature values in human-readable format\n",
    "- SHAP waterfall plot (loaded from `figures/shap/shap_waterfall_cases.png`)\n",
    "- Plain-English explanation of why the model made its decision\n",
    "- Key risk drivers as bullet points\n",
    "- Recommended improvements (for missed fraud cases)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tab 4: Regulatory Compliance\n",
    "\n",
    "**Purpose:** Document model governance readiness for banking regulators and internal audit.\n",
    "\n",
    "**Regulatory Frameworks Addressed:**\n",
    "- **Federal Reserve SR 11-7** -- Model Risk Management guidance\n",
    "- **OCC 2011-12** -- Supervisory guidance on model risk management\n",
    "- **ECOA / Fair Lending** -- Anti-discrimination in credit decisions\n",
    "- **GDPR Art. 22** -- Right to explanation for automated decisions\n",
    "\n",
    "**Components:**\n",
    "1. **SR 11-7 Checklist**: 8 completed items + 4 pending items with checkboxes\n",
    "2. **Fair Lending Review**: Risk assessment for each of the 7 model features\n",
    "3. **Model Governance Framework**: Model identification, risk classification, monitoring schedule, key assumptions\n",
    "4. **Right-to-Explanation**: How SHAP values support customer dispute resolution\n",
    "5. **Data Lineage**: Full processing pipeline from raw data to model predictions\n",
    "\n",
    "**Why this matters for banking roles:**\n",
    "Demonstrating regulatory awareness differentiates a data scientist from a pure ML engineer. Banks need practitioners who understand that a model is not deployed until it passes compliance review.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Deployment\n",
    "\n",
    "### Requirements File\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "%%writefile requirements.txt\n",
    "streamlit>=1.30.0\n",
    "pandas>=2.0.0\n",
    "numpy>=1.24.0\n",
    "matplotlib>=3.7.0\n",
    "seaborn>=0.12.0\n",
    "scikit-learn>=1.3.0\n",
    "xgboost>=2.0.0\n",
    "joblib>=1.3.0\n",
    "Pillow>=10.0.0\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Locally\n",
    "\n",
    "```bash\n",
    "# From the project root directory:\n",
    "cd notebooks/dashboard\n",
    "streamlit run dashboard_app.py\n",
    "```\n",
    "\n",
    "The dashboard will open in your browser at `http://localhost:8501`.\n",
    "\n",
    "**Required files (relative to `notebooks/dashboard/`):**\n",
    "- `../../models/xgboost_final.pkl`\n",
    "- `../../models/scaler.pkl`\n",
    "- `../../models/threshold_config.pkl`\n",
    "- `../../data/processed/test.csv`\n",
    "- `../../figures/shap/*.png` (optional, fallback to model importances)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Verify the dashboard app file was created\n",
    "from pathlib import Path\n",
    "\n",
    "app_file = Path(\"dashboard_app.py\")\n",
    "req_file = Path(\"requirements.txt\")\n",
    "\n",
    "print(\"Generated Files:\")\n",
    "for f in [app_file, req_file]:\n",
    "    if f.exists():\n",
    "        size_kb = f.stat().st_size / 1024\n",
    "        print(f\"  [OK] {f.name} ({size_kb:.1f} KB)\")\n",
    "    else:\n",
    "        print(f\"  [MISSING] {f.name}\")\n",
    "\n",
    "print(\"\\nTo launch the dashboard:\")\n",
    "print(\"  streamlit run dashboard_app.py\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streamlit Cloud Deployment\n",
    "\n",
    "**Steps to deploy on Streamlit Community Cloud:**\n",
    "\n",
    "1. **Push to GitHub**: Ensure all model artifacts, data, and SHAP figures are committed to the repository\n",
    "\n",
    "2. **Go to** [share.streamlit.io](https://share.streamlit.io)\n",
    "\n",
    "3. **Configure the app:**\n",
    "   - Repository: `JuanCRuizA/Agent-Fraud-Sentinel`\n",
    "   - Branch: `main`\n",
    "   - Main file path: `notebooks/dashboard/dashboard_app.py`\n",
    "\n",
    "4. **Requirements**: The `requirements.txt` in `notebooks/dashboard/` will be detected automatically. If Streamlit Cloud looks for a root-level requirements file, copy it to the project root.\n",
    "\n",
    "**Notes:**\n",
    "- The test dataset (`test.csv`, ~50 MB) and model files (`*.pkl`) must be in the repository for the app to load data\n",
    "- Streamlit Cloud provides 1 GB of memory; the test set (118K rows x 7 features) fits comfortably\n",
    "- `@st.cache_resource` and `@st.cache_data` decorators ensure the model and data are loaded only once per session\n",
    "- For large-scale deployment, consider storing data in a cloud database and model in an artifact registry\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "### Dashboard Features\n",
    "\n",
    "| Tab | Content | Audience |\n",
    "|-----|---------|----------|\n",
    "| Executive Summary | KPIs, risk distribution, cost analysis | Business stakeholders |\n",
    "| Model Performance | Confusion matrix, ROC/PR curves, feature importance | Data science teams |\n",
    "| Case Study Explorer | 6 case studies with SHAP explanations | Fraud analysts |\n",
    "| Regulatory Compliance | SR 11-7, fair lending, audit trail | Compliance officers |\n",
    "\n",
    "### Interactive Controls\n",
    "\n",
    "| Control | Location | Effect |\n",
    "|---------|----------|--------|\n",
    "| Risk Threshold slider | Sidebar | Updates all metrics, confusion matrix, and cost analysis |\n",
    "| Sample Size selector | Sidebar | Subsamples test data for faster exploration |\n",
    "| Case Study dropdown | Tab 3 | Selects individual transaction for detailed analysis |\n",
    "\n",
    "### Artifacts Produced\n",
    "\n",
    "| File | Description |\n",
    "|------|-------------|\n",
    "| `dashboard_app.py` | Complete Streamlit application |\n",
    "| `requirements.txt` | Python dependencies for deployment |\n",
    "\n",
    "### Production Readiness\n",
    "\n",
    "- Uses actual model outputs (no placeholder data)\n",
    "- Cost-sensitive threshold configuration ($75 FN, $10 FP)\n",
    "- SHAP-based explainability for individual transactions\n",
    "- Regulatory compliance documentation (SR 11-7, fair lending)\n",
    "- Footer with project attribution on every tab\n",
    "- Deployment-ready for Streamlit Cloud\n",
    "\n",
    "---\n",
    "\n",
    "**Notebook completed:** Phase 5 -- Streamlit Dashboard Prototype  \n",
    "**Status:** Ready for deployment and portfolio presentation  \n",
    "**Next steps:** Deploy to Streamlit Cloud, gather feedback, iterate\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}