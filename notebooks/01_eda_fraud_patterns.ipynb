{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IEEE-CIS Fraud Detection - EDA: Fraud Patterns\n",
    "\n",
    "**Objective**: Identify key fraud signals in the IEEE-CIS dataset to guide feature engineering.\n",
    "\n",
    "**Focus Areas**:\n",
    "- Fraud rate and class distribution\n",
    "- Top features correlated with fraud\n",
    "- Missing data patterns\n",
    "- Transaction amount distribution\n",
    "- Temporal fraud patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "DATA_PATH = Path('../data/raw/')\n",
    "\n",
    "print(\"Loading transaction data...\")\n",
    "train_transaction = pd.read_csv(DATA_PATH / 'train_transaction.csv')\n",
    "print(f\"Transaction shape: {train_transaction.shape}\")\n",
    "\n",
    "print(\"\\nLoading identity data...\")\n",
    "train_identity = pd.read_csv(DATA_PATH / 'train_identity.csv')\n",
    "print(f\"Identity shape: {train_identity.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge on TransactionID\n",
    "df = train_transaction.merge(train_identity, on='TransactionID', how='left')\n",
    "print(f\"Merged dataset shape: {df.shape}\")\n",
    "print(f\"Total features: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fraud Rate Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate fraud statistics\n",
    "fraud_count = df['isFraud'].sum()\n",
    "total_count = len(df)\n",
    "fraud_rate = fraud_count / total_count * 100\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"FRAUD STATISTICS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Total transactions: {total_count:,}\")\n",
    "print(f\"Fraudulent: {fraud_count:,} ({fraud_rate:.2f}%)\")\n",
    "print(f\"Legitimate: {total_count - fraud_count:,} ({100-fraud_rate:.2f}%)\")\n",
    "print(f\"\\nClass imbalance ratio: 1:{int((total_count-fraud_count)/fraud_count)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Class Distribution Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Bar chart\n",
    "class_counts = df['isFraud'].value_counts()\n",
    "colors = ['#2ecc71', '#e74c3c']\n",
    "axes[0].bar(['Legitimate (0)', 'Fraud (1)'], class_counts.values, color=colors)\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('Transaction Class Distribution')\n",
    "for i, v in enumerate(class_counts.values):\n",
    "    axes[0].text(i, v + 5000, f'{v:,}', ha='center', fontweight='bold')\n",
    "\n",
    "# Pie chart (log scale effect via explode)\n",
    "axes[1].pie([total_count - fraud_count, fraud_count], \n",
    "            labels=['Legitimate', 'Fraud'],\n",
    "            autopct='%1.2f%%', colors=colors, explode=(0, 0.1),\n",
    "            shadow=True, startangle=90)\n",
    "axes[1].set_title('Fraud Rate Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/processed/class_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Top 10 Features by Correlation with isFraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlations with isFraud (numeric columns only)\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numeric_cols.remove('isFraud')\n",
    "numeric_cols.remove('TransactionID')\n",
    "\n",
    "correlations = df[numeric_cols].corrwith(df['isFraud']).abs().sort_values(ascending=False)\n",
    "\n",
    "# Top 10 features\n",
    "top_10_features = correlations.head(10)\n",
    "print(\"TOP 10 FEATURES BY CORRELATION WITH FRAUD\")\n",
    "print(\"=\"*50)\n",
    "for i, (feat, corr) in enumerate(top_10_features.items(), 1):\n",
    "    print(f\"{i:2}. {feat:<20} | Correlation: {corr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top correlations\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = plt.cm.RdYlGn_r(np.linspace(0.2, 0.8, 10))\n",
    "bars = plt.barh(top_10_features.index[::-1], top_10_features.values[::-1], color=colors[::-1])\n",
    "plt.xlabel('Absolute Correlation with isFraud')\n",
    "plt.title('Top 10 Features Correlated with Fraud')\n",
    "for bar, val in zip(bars, top_10_features.values[::-1]):\n",
    "    plt.text(val + 0.002, bar.get_y() + bar.get_height()/2, f'{val:.3f}', va='center')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/processed/top_correlations.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Missing Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate missing percentages\n",
    "missing_pct = (df.isnull().sum() / len(df) * 100).sort_values(ascending=False)\n",
    "high_missing = missing_pct[missing_pct > 50]\n",
    "\n",
    "print(f\"FEATURES WITH >50% MISSING DATA: {len(high_missing)}\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nTotal features: {df.shape[1]}\")\n",
    "print(f\"Features >50% missing: {len(high_missing)} ({len(high_missing)/df.shape[1]*100:.1f}%)\")\n",
    "print(f\"Features >75% missing: {len(missing_pct[missing_pct > 75])}\")\n",
    "print(f\"Features >90% missing: {len(missing_pct[missing_pct > 90])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize missing data distribution\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Histogram of missing percentages\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(missing_pct, bins=20, color='steelblue', edgecolor='black')\n",
    "plt.axvline(x=50, color='red', linestyle='--', label='50% threshold')\n",
    "plt.xlabel('Missing Percentage')\n",
    "plt.ylabel('Number of Features')\n",
    "plt.title('Distribution of Missing Values Across Features')\n",
    "plt.legend()\n",
    "\n",
    "# Top 15 features with most missing\n",
    "plt.subplot(1, 2, 2)\n",
    "top_missing = missing_pct.head(15)\n",
    "plt.barh(top_missing.index[::-1], top_missing.values[::-1], color='coral')\n",
    "plt.xlabel('Missing %')\n",
    "plt.title('Top 15 Features by Missing Data')\n",
    "plt.axvline(x=50, color='red', linestyle='--')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/processed/missing_data.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Transaction Amount Distribution by Fraud Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transaction amount statistics\n",
    "print(\"TRANSACTION AMOUNT STATISTICS\")\n",
    "print(\"=\"*50)\n",
    "for label, group in df.groupby('isFraud')['TransactionAmt']:\n",
    "    status = 'Fraud' if label == 1 else 'Legitimate'\n",
    "    print(f\"\\n{status} Transactions:\")\n",
    "    print(f\"  Mean:   ${group.mean():,.2f}\")\n",
    "    print(f\"  Median: ${group.median():,.2f}\")\n",
    "    print(f\"  Std:    ${group.std():,.2f}\")\n",
    "    print(f\"  Max:    ${group.max():,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Distribution plot (log scale for visibility)\n",
    "for fraud_val, color, label in [(0, '#2ecc71', 'Legitimate'), (1, '#e74c3c', 'Fraud')]:\n",
    "    data = df[df['isFraud'] == fraud_val]['TransactionAmt']\n",
    "    axes[0].hist(np.log1p(data), bins=50, alpha=0.6, color=color, label=label, density=True)\n",
    "\n",
    "axes[0].set_xlabel('Log(Transaction Amount + 1)')\n",
    "axes[0].set_ylabel('Density')\n",
    "axes[0].set_title('Transaction Amount Distribution (Log Scale)')\n",
    "axes[0].legend()\n",
    "\n",
    "# Box plot comparison\n",
    "df_sample = df.sample(n=min(50000, len(df)), random_state=42)\n",
    "sns.boxplot(data=df_sample, x='isFraud', y='TransactionAmt', ax=axes[1], palette=['#2ecc71', '#e74c3c'])\n",
    "axes[1].set_xticklabels(['Legitimate', 'Fraud'])\n",
    "axes[1].set_ylabel('Transaction Amount ($)')\n",
    "axes[1].set_title('Transaction Amount by Fraud Status')\n",
    "axes[1].set_ylim(0, 1000)  # Focus on main distribution\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/processed/amount_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Temporal Patterns: Fraud by Hour and Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TransactionDT is seconds from a reference time\n",
    "# Extract hour of day and day of week\n",
    "START_DATE = '2017-12-01'  # Common assumption for IEEE-CIS dataset\n",
    "df['datetime'] = pd.to_datetime(START_DATE) + pd.to_timedelta(df['TransactionDT'], unit='s')\n",
    "df['hour'] = df['datetime'].dt.hour\n",
    "df['dayofweek'] = df['datetime'].dt.dayofweek\n",
    "df['day'] = df['datetime'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Fraud rate by hour\n",
    "hourly_fraud = df.groupby('hour')['isFraud'].mean() * 100\n",
    "axes[0].bar(hourly_fraud.index, hourly_fraud.values, color='steelblue', edgecolor='black')\n",
    "axes[0].axhline(y=fraud_rate, color='red', linestyle='--', label=f'Overall Rate ({fraud_rate:.2f}%)')\n",
    "axes[0].set_xlabel('Hour of Day')\n",
    "axes[0].set_ylabel('Fraud Rate (%)')\n",
    "axes[0].set_title('Fraud Rate by Hour of Day')\n",
    "axes[0].set_xticks(range(0, 24, 2))\n",
    "axes[0].legend()\n",
    "\n",
    "# Fraud rate by day of week\n",
    "daily_fraud = df.groupby('dayofweek')['isFraud'].mean() * 100\n",
    "days = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "axes[1].bar(days, daily_fraud.values, color='coral', edgecolor='black')\n",
    "axes[1].axhline(y=fraud_rate, color='red', linestyle='--', label=f'Overall Rate ({fraud_rate:.2f}%)')\n",
    "axes[1].set_xlabel('Day of Week')\n",
    "axes[1].set_ylabel('Fraud Rate (%)')\n",
    "axes[1].set_title('Fraud Rate by Day of Week')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/processed/temporal_patterns.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of temporal patterns\n",
    "print(\"TEMPORAL FRAUD PATTERNS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nHighest fraud hours: {hourly_fraud.nlargest(3).index.tolist()}\")\n",
    "print(f\"Lowest fraud hours: {hourly_fraud.nsmallest(3).index.tolist()}\")\n",
    "print(f\"\\nHighest fraud days: {[days[i] for i in daily_fraud.nlargest(3).index.tolist()]}\")\n",
    "print(f\"Lowest fraud days: {[days[i] for i in daily_fraud.nsmallest(3).index.tolist()]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary Statistics Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary statistics\n",
    "summary = pd.DataFrame({\n",
    "    'Metric': [\n",
    "        'Total Transactions', 'Fraud Transactions', 'Fraud Rate (%)',\n",
    "        'Class Imbalance Ratio', 'Total Features', 'Features >50% Missing',\n",
    "        'Avg Fraud Amount ($)', 'Avg Legitimate Amount ($)',\n",
    "        'Peak Fraud Hour', 'Peak Fraud Day'\n",
    "    ],\n",
    "    'Value': [\n",
    "        f\"{total_count:,}\", f\"{fraud_count:,}\", f\"{fraud_rate:.2f}\",\n",
    "        f\"1:{int((total_count-fraud_count)/fraud_count)}\", f\"{df.shape[1]}\", f\"{len(high_missing)}\",\n",
    "        f\"{df[df['isFraud']==1]['TransactionAmt'].mean():.2f}\",\n",
    "        f\"{df[df['isFraud']==0]['TransactionAmt'].mean():.2f}\",\n",
    "        f\"{hourly_fraud.idxmax()}:00\", f\"{days[daily_fraud.idxmax()]}\"\n",
    "    ]\n",
    "})\n",
    "print(summary.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Key Findings & Top Features for Feature Engineering\n",
    "\n",
    "### Key Findings:\n",
    "1. **Severe class imbalance** - Will need SMOTE or class weights\n",
    "2. **Many high-missing features** - Consider dropping features >75% missing or using imputation\n",
    "3. **Amount patterns differ** - Fraudulent transactions show different amount distributions\n",
    "4. **Temporal signals exist** - Hour and day of week have fraud rate variations\n",
    "\n",
    "### Top 10 Features for Feature Engineering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save top features list\n",
    "top_features_list = top_10_features.index.tolist()\n",
    "print(\"TOP 10 FEATURES FOR FEATURE ENGINEERING\")\n",
    "print(\"=\"*50)\n",
    "for i, feat in enumerate(top_features_list, 1):\n",
    "    corr = top_10_features[feat]\n",
    "    missing = missing_pct.get(feat, 0)\n",
    "    print(f\"{i:2}. {feat:<20} | Corr: {corr:.4f} | Missing: {missing:.1f}%\")\n",
    "\n",
    "# Save to file for reference\n",
    "pd.DataFrame({'feature': top_features_list, 'correlation': top_10_features.values}).to_csv(\n",
    "    '../data/processed/top_features.csv', index=False\n",
    ")\n",
    "print(\"\\n[Saved to data/processed/top_features.csv]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Next Steps**: Use these top features as starting point for feature engineering in Phase 2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
